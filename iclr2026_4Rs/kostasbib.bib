@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}

@article{pflug1986stochastic,
  title={Stochastic minimization with constant step-size: asymptotic laws},
  author={Pflug, Georg Ch},
  journal={SIAM Journal on Control and Optimization},
  volume={24},
  number={4},
  pages={655--666},
  year={1986},
  publisher={SIAM}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{yu2021analysis,
  title={An analysis of constant step size SGD in the non-convex regime: Asymptotic normality and bias},
  author={Yu, Lu and Balasubramanian, Krishnakumar and Volgushev, Stanislav and Erdogdu, Murat A},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4234--4248},
  year={2021}
}

@inproceedings{
cho2023sgda,
title={{SGDA} with shuffling: faster convergence for nonconvex-P{\L} minimax optimization},
author={Hanseul Cho and Chulhee Yun},
booktitle={ICLR},
year={2023}
}


@inproceedings{azizian2020tight,
  title={A tight and unified analysis of gradient-based methods for a whole spectrum of differentiable games},
  author={Azizian, Wa{\"\i}ss and Mitliagkas, Ioannis and Lacoste-Julien, Simon and Gidel, Gauthier},
  booktitle={International conference on artificial intelligence and statistics},
  pages={2863--2873},
  year={2020},
  organization={PMLR}
}
@article{hsieh2019convergence,
  title={On the convergence of single-call stochastic extra-gradient methods},
  author={Hsieh, Yu-Guan and Iutzeler, Franck and Malick, J{\'e}r{\^o}me and Mertikopoulos, Panayotis},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{bauschke2017convex,
  title={Convex Analysis and Monotone Operator Theory in Hilbert Spaces, 2011 Springer},
  author={Bauschke, HH and Combettes, PL},
  journal={New York},
  year={2017}
}

@book{facchinei2003finite,
  title={Finite-dimensional variational inequalities and complementarity problems},
  author={Facchinei, Francisco and Pang, Jong-Shi},
  year={2003},
  publisher={Springer}
}

@article{dantzig1968complementary,
  title={Complementary pivot theory of. mathematical programming},
  author={Dantzig, George B and Cottle, RW},
  journal={Mathematics of the decision sciences, part},
  volume={1},
  pages={115--136},
  year={1968}
}

@article{syrgkanis2015fast,
  title={Fast convergence of regularized learning in games},
  author={Syrgkanis, Vasilis and Agarwal, Alekh and Luo, Haipeng and Schapire, Robert E},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@article{stampacchia1964formes,
  title={Formes bilineaires coercitives sur les ensembles convexes},
  author={Stampacchia, Guido},
  journal={Comptes Rendus Hebdomadaires Des Seances De L Academie Des Sciences},
  volume={258},
  number={18},
  pages={4413},
  year={1964},
  publisher={GAUTHIER-VILLARS/EDITIONS ELSEVIER 23 RUE LINOIS, 75015 PARIS, FRANCE}
}

@inproceedings{loizou2020stochastic,
  title={Stochastic hamiltonian gradient methods for smooth games},
  author={Loizou, Nicolas and Berard, Hugo and Jolicoeur-Martineau, Alexia and Vincent, Pascal and Lacoste-Julien, Simon and Mitliagkas, Ioannis},
  booktitle={ICML},
  year={2020}
}

@article{chen1997convergence,
  title={Convergence rates in forward--backward splitting},
  author={Chen, George HG and Rockafellar, R Tyrrell},
  journal={SIAM Journal on Optimization},
  volume={7},
  number={2},
  pages={421--444},
  year={1997},
  publisher={SIAM}
}

@inproceedings{
pethick2022escaping,
title={Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems},
author={Thomas Pethick and Puya Latafat and Panos Patrinos and Olivier Fercoq and Volkan Cevher},
booktitle={ICLR},
year={2022}
}
@inproceedings{yu2022fast,
  title={Fast Distributionally Robust Learning with Variance-Reduced Min-Max Optimization},
  author={Yu, Yaodong and Lin, Tianyi and Mazumdar, Eric V and Jordan, Michael},
  booktitle={AISTATS},
  year={2022}
}
@inproceedings{mishchenko2020revisiting,
  title={Revisiting stochastic extragradient},
  author={Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  booktitle={AISTATS},
  year={2020}
}

@inproceedings{namkoong2016stochastic,
  title={Stochastic gradient methods for distributionally robust optimization with f-divergences},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={NeurIPS},
  year={2016}
}

@article{durmus2016stochastic,
  title={Stochastic gradient richardson-romberg markov chain monte carlo},
  author={Durmus, Alain and Simsekli, Umut and Moulines, Eric and Badeau, Roland and Richard, Ga{\"e}l},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{brown2020combining,
  title={Combining deep reinforcement learning and search for imperfect-information games},
  author={Brown, Noam and Bakhtin, Anton and Lerer, Adam and Gong, Qucheng},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{sokota2022unified,
  title={A unified approach to reinforcement learning, quantal response equilibria, and two-player zero-sum games},
  author={Sokota, Samuel and D'Orazio, Ryan and Kolter, J Zico and Loizou, Nicolas and Lanctot, Marc and Mitliagkas, Ioannis and Brown, Noam and Kroer, Christian},
  booktitle={ICLR},
  year={2023}
}

@article{dieuleveut2020bridging,
  title={Bridging the gap between constant step size stochastic gradient descent and Markov chains},
  author={Dieuleveut, Aymeric and Durmus, Alain and Bach, Francis},
  year={2020}
}


@inproceedings{wang2021adversarial,
  title={Adversarial attack generation empowered by min-max optimization},
  author={Wang, Jingkang and Zhang, Tianyun and Liu, Sijia and Chen, Pin-Yu and Xu, Jiacen and Fardad, Makan and Li, Bo},
  booktitle={NeurIPS},
  year={2021}
}

@article{mangold2024refined,
  title={Refined Analysis of Federated Averaging's Bias and Federated Richardson-Romberg Extrapolation},
  author={Mangold, Paul and Durmus, Alain and Dieuleveut, Aymeric and Samsonov, Sergey and Moulines, Eric},
  journal={arXiv preprint arXiv:2412.01389},
  year={2024}
}

@book{hildebrand1987introduction,
  title={Introduction to numerical analysis},
  author={Hildebrand, Francis Begnaud},
  year={1987},
  publisher={Courier Corporation}
}

@article{sheshukova2024nonasymptotic,
  title={Nonasymptotic analysis of stochastic gradient descent with the richardson-romberg extrapolation},
  author={Sheshukova, Marina and Belomestny, Denis and Durmus, Alain and Moulines, Eric and Naumov, Alexey and Samsonov, Sergey},
  journal={arXiv preprint arXiv:2410.05106},
  year={2024}
}

@article{talay1990expansion,
  title={Expansion of the global error for numerical schemes solving stochastic differential equations},
  author={Talay, Denis and Tubaro, Luciano},
  journal={Stochastic analysis and applications},
  volume={8},
  number={4},
  pages={483--509},
  year={1990},
  publisher={Taylor \& Francis}
}

@inproceedings{goodfellow2014generative,
title={Generative adversarial nets},
author={Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle={NeurIPS},
year={2014}
}
@incollection{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  booktitle={Neural networks: tricks of the trade: second edition},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

@article{bally1996law,
  title={The law of the Euler scheme for stochastic differential equations: I. Convergence rate of the distribution function},
  author={Bally, Vlad and Talay, Denis},
  journal={Probability theory and related fields},
  volume={104},
  number={1},
  pages={43--60},
  year={1996},
  publisher={Springer}
}

@article{allmeier2024computing,
  title={Computing the bias of constant-step stochastic approximation with markovian noise},
  author={Allmeier, Sebastian and Gast, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={137873--137902},
  year={2024}
}

@article{zhang2024constant,
  title={Constant stepsize q-learning: Distributional convergence, bias and extrapolation},
  author={Zhang, Yixuan and Xie, Qiaomin},
  journal={arXiv preprint arXiv:2401.13884},
  year={2024}
}

@article{romberg1955vereinfachte,
  title={Vereinfachte numerische integration},
  author={Romberg, Werner},
  journal={Norske Vid. Selsk. Forh.},
  volume={28},
  pages={30--36},
  year={1955},
  publisher={Trondheim}
}

@article{richardson1911ix,
  title={IX. The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam},
  author={Richardson, Lewis Fry},
  journal={Philosophical Transactions of the Royal Society of London. Series A, containing papers of a mathematical or physical character},
  volume={210},
  number={459-470},
  pages={307--357},
  year={1911},
  publisher={The Royal Society London}
}

@inproceedings{huo2023bias,
  title={Bias and extrapolation in Markovian linear stochastic approximation with constant stepsizes},
  author={Huo, Dongyan and Chen, Yudong and Xie, Qiaomin},
  booktitle={Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
  pages={81--82},
  year={2023}
}
@article{kwon2024two,
  title={Two-timescale linear stochastic approximation: Constant stepsizes go a long way},
  author={Kwon, Jeongyeol and Dotson, Luke and Chen, Yudong and Xie, Qiaomin},
  journal={arXiv preprint arXiv:2410.13067},
  year={2024}
}

@article{giannou2022convergence,
  title={On the convergence of policy gradient methods to Nash equilibria in general stochastic games},
  author={Giannou, Angeliki and Lotidis, Kyriakos and Mertikopoulos, Panayotis and Vlatakis-Gkaragkounis, Emmanouil-Vasileios},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7128--7141},
  year={2022}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, A. and Makelov, A. and Schmidt, L. and Tsipras, D. and Vladu, A.},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={ICML},
  year={2017}
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@article{han2023riemannian,
  title={Riemannian Hamiltonian methods for min-max optimization on manifolds},
  author={Han, Andi and Mishra, Bamdev and Jawanpuria, Pratik and Kumar, Pawan and Gao, Junbin},
  journal={SIAM Journal on Optimization},
  volume={33},
  number={3},
  pages={1797--1827},
  year={2023},
  publisher={SIAM}
}

@inproceedings{balduzzi2018mechanics,
  title={The mechanics of n-player differentiable games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  booktitle={ICML},
  year={2018}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{gorbunov2022last,
  title={Last-iterate convergence of optimistic gradient method for monotone variational inequalities},
  author={Gorbunov, Eduard and Taylor, Adrien and Gidel, Gauthier},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{gorbunov2022stochastic,
  title={Stochastic extragradient: General analysis and improved rates},
  author={Gorbunov, Eduard and Berard, Hugo and Gidel, Gauthier and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2022}
}

@inproceedings{beznosikov2022stochastic,
  title={Stochastic gradient descent-ascent: Unified theory and new efficient methods},
  author={Beznosikov, Aleksandr and Gorbunov, Eduard and Berard, Hugo and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2023}
}
@inproceedings{daskalakis2018limit,
  title={The limit points of (optimistic) gradient descent in min-max optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  booktitle={NeurIPS},
  year={2018}
}

@article{popov1980modification,
  title={A modification of the Arrow-Hurwicz method for search of saddle points},
  author={Popov, Leonid Denisovich},
  journal={Mathematical notes of the Academy of Sciences of the USSR},
  volume={28},
  number={5},
  pages={845--848},
  year={1980},
  publisher={Springer}
}

@misc{diakonikolas2021efficient,
      title={Efficient Methods for Structured Nonconvex-Nonconcave Min-Max Optimization}, 
      author={Jelena Diakonikolas and Constantinos Daskalakis and Michael I. Jordan},
      year={2021},
        booktitle={AISTATS},
}

@misc{huang2023monotonevariationalinequalitiessolution,
      title={Beyond Monotone Variational Inequalities: Solution Methods and Iteration Complexities}, 
      author={Kevin Huang and Shuzhong Zhang},
      year={2023}
}
@misc{karimi2020linearconvergencegradientproximalgradient,
      title={Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\L{}ojasiewicz Condition}, 
      author={Hamed Karimi and Julie Nutini and Mark Schmidt},
      year={2020}
}

@inproceedings{gorbunov2022extragradient,
  title={Extragradient method: O (1/k) last-iterate convergence for monotone variational inequalities and connections with cocoercivity},
  author={Gorbunov, Eduard and Loizou, Nicolas and Gidel, Gauthier},
  booktitle={AISTATS},
    year={2022}
}

@inproceedings{pethick2023solving,
  title={Solving stochastic weak Minty variational inequalities without increasing batch size},
  author={Pethick, Thomas Michaelsen and Fercoq, Olivier and Latafat, Puya and Patrinos, Panagiotis and Cevher, Volkan},
  booktitle={ICLR},
  year={2023}
}

@article{cai2023empirical,
  title={Empirical Risk Minimization with Shuffled SGD: A Primal-Dual Perspective and Improved Bounds},
  author={Cai, Xufeng and Lin, Cheuk Yin and Diakonikolas, Jelena},
  journal={arXiv:2306.12498},
  year={2023}
}

@article{song2020optimistic,
  title={Optimistic dual extrapolation for coherent non-monotone variational inequalities},
  author={Song, Chaobing and Zhou, Zhengyuan and Zhou, Yichao and Jiang, Yong and Ma, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14303--14314},
  year={2020}
}

@article{erdogdu2018global,
  title={Global non-convex optimization with discretized diffusions},
  author={Erdogdu, Murat A and Mackey, Lester and Shamir, Ohad},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@article{tan2023online,
  title={Online stochastic gradient descent with arbitrary initialization solves non-smooth, non-convex phase retrieval},
  author={Tan, Yan Shuo and Vershynin, Roman},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={58},
  pages={1--47},
  year={2023}
}
@article{rakhlin2011making,
  title={Making gradient descent optimal for strongly convex stochastic optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  journal={arXiv preprint arXiv:1109.5647},
  year={2011}
}

@inproceedings{raginsky2017non,
  title={Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1674--1703},
  year={2017},
  organization={PMLR}
}
@article{MalickMertikopoulos2024,
  title   = {The Global Convergence Time of Stochastic Gradient Descent in Non-Convex Landscapes: Sharp Estimates via Large Deviations},
  author  = {J{\'e}r{\^o}me Malick and Panayotis Mertikopoulos},
  journal = {arXiv preprint: 2503.16398}, 
  year    = {2024}
}

@article{azizian2024long,
  title={What is the long-run distribution of stochastic gradient descent? A large deviations analysis},
  author={Azizian, Wa{\"\i}ss and Iutzeler, Franck and Malick, J{\'e}r{\^o}me and Mertikopoulos, Panayotis},
  journal={arXiv preprint arXiv:2406.09241},
  year={2024}
}

@article{nguyen2021unified,
  title={A unified convergence analysis for shuffling-type gradient methods},
  author={Nguyen, Lam M and Tran-Dinh, Quoc and Phan, Dzung T and Nguyen, Phuong Ha and Van Dijk, Marten},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={9397--9440},
  year={2021},
  publisher={JMLRORG}
}



@article{mertikopoulos2019learning,
  title={Learning in games with continuous action sets and unknown payoff functions},
  author={Mertikopoulos, Panayotis and Zhou, Zhengyuan},
  journal={Mathematical Programming},
  volume={173},
  number={1},
  pages={465--507},
  year={2019},
  publisher={Springer}
}
@inproceedings{beznosikov2022distributed,
  title={Distributed methods with compressed communication for solving variational inequalities, with theoretical guarantees},
  author={Beznosikov, Aleksandr and Richt{\'a}rik, Peter and Diskin, Michael and Ryabinin, Max and Gasnikov, Alexander},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{choudhury2023single,
 title={Single-Call Stochastic Extragradient Methods for Structured Non-monotone Variational Inequalities: Improved Analysis under Weaker Conditions},
 author={Sayantan Choudhury and Eduard Gorbunov and Nicolas Loizou},
 booktitle={NeurIPS},
 year={2023}
}

@inproceedings{zhang2023communication,
  title={Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates},
  author={Zhang, Siqi and Choudhury, Sayantan and Stich, Sebastian U and Loizou, Nicolas},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{li2022convergence,
  title={On the convergence of stochastic extragradient for bilinear games using restarted iteration averaging},
  author={Li, Chris Junchi and Yu, Yaodong and Loizou, Nicolas and Gidel, Gauthier and Ma, Yi and Le Roux, Nicolas and Jordan, Michael},
  booktitle={AISTATS},
    year={2022}
}

@inproceedings{mishchenko2020random,
  title={Random reshuffling: Simple analysis with vast improvements},
  author={Mishchenko, Konstantin and Khaled, Ahmed and Richt{\'a}rik, Peter},
  booktitle={NeurIPS},
  year={2020}
}
@article{korpelevich1976extragradient,
  title={The extragradient method for finding saddle points and other problems},
  author={Korpelevich, Galina M},
  journal={Matecon},
  volume={12},
  pages={747--756},
  year={1976}
}

@article{juditsky2011solving,
  title={Solving variational inequalities with stochastic mirror-prox algorithm},
  author={Juditsky, Anatoli and Nemirovski, Arkadi and Tauvel, Claire},
  journal={Stochastic Systems},
  volume={1},
  number={1},
  pages={17--58},
  year={2011},
  publisher={INFORMS}
}
@inproceedings{ahn2020sgd,
  title={Sgd with shuffling: optimal rates without component convexity and large epoch requirements},
  author={Ahn, Kwangjun and Yun, Chulhee and Sra, Suvrit},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{lin2020finite,
  title={Finite-time last-iterate convergence for multi-agent learning in games},
  author={Lin, Tianyi and Zhou, Zhengyuan and Mertikopoulos, Panayotis and Jordan, Michael},
  booktitle={ICML},
  year={2020}
}
@inproceedings{lin2020gradient,
  title={On gradient descent ascent for nonconvex-concave minimax problems},
  author={Lin, Tianyi and Jin, Chi and Jordan, Michael},
  booktitle={ICML},
    year={2020}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={AISTATS},
  year={2017}
}
@article{necoara2019linear,
  title={Linear convergence of first order methods for non-strongly convex optimization},
  author={Necoara, Ion and Nesterov, Yu and Glineur, Francois},
  journal={Mathematical Programming},
  volume={175},
  pages={69--107},
  year={2019},
  publisher={Springer}
}
@inproceedings{hsieh2020explore,
  title={Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling},
  author={Hsieh, Yu-Guan and Iutzeler, Franck and Malick, J{\'e}r{\^o}me and Mertikopoulos, Panayotis},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{beznosikov2023stochastic,
  title={Stochastic gradient descent-ascent: Unified theory and new efficient methods},
  author={Beznosikov, Aleksandr and Gorbunov, Eduard and Berard, Hugo and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2023}
}
@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={ICLR},
year={2018}
}
@inproceedings{
chavdarova2021taming,
title={Taming {GAN}s with Lookahead-Minmax},
author={Tatjana Chavdarova and Matteo Pagliardini and Sebastian U Stich and Fran{\c{c}}ois Fleuret and Martin Jaggi},
booktitle={ICLR},
year={2021}
}
@article{Neumann1928,
author = {Neumann, J. von},
journal = {Mathematische Annalen},
pages = {295-320},
title = {Zur Theorie der Gesellschaftsspiele},
volume = {100},
year = {1928},
}
@article{Blackwell1956AnAO,
  title={An analog of the minimax theorem for vector payoffs.},
  author={David Blackwell},
  journal={Pacific Journal of Mathematics},
  year={1956},
  volume={6},
  pages={1-8}
}
@article{
bohm2023solving,
title={Solving Nonconvex-Nonconcave Min-Max Problems exhibiting Weak Minty Solutions},
author={Axel B{\"o}hm},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023}
}
@misc{cai2022tight,
      title={Tight Last-Iterate Convergence of the Extragradient and the Optimistic Gradient Descent-Ascent Algorithm for Constrained Monotone Variational Inequalities}, 
      author={Yang Cai and Argyris Oikonomou and Weiqiang Zheng},
      year={2022},
      archivePrefix={arXiv },
      eprint={2204.09228}
}
@inproceedings{das2022sampling,
  title={Sampling without replacement leads to faster rates in finite-sum minimax optimization},
  author={Das, Aniket and Sch{\"o}lkopf, Bernhard and Muehlebach, Michael},
  booktitle={NeurIPS},
  year={2022}
}
@inproceedings{Jain2019SGDWR,
  title={SGD without Replacement: Sharper Rates for General Smooth Convex Functions},
  author={Prateek Jain and Dheeraj M. Nagaraj and Praneeth Netrapalli},
  booktitle={ICML},
  year={2019}
}
@inproceedings{Yang2020GlobalCA,
  title={Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems},
  author={Junchi Yang and Negar Kiyavash and Niao He},
  booktitle={NeurIPS},
  year={2020}
}
@article{gurbuzbalaban2021random,
  title={Why random reshuffling beats stochastic gradient descent},
  author={G{\"u}rb{\"u}zbalaban, Mert and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={Mathematical Programming},
  volume={186},
  pages={49--84},
  year={2021},
  publisher={Springer}
}

@inproceedings{Yang2020GlobalCA,
  title={Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems},
  author={Junchi Yang and Negar Kiyavash and Niao He},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{haochen2019random,
  title={Random shuffling beats sgd after finite epochs},
  author={Haochen, Jeff and Sra, Suvrit},
  booktitle={ICML},
  year={2019}
}
@article{RRSGDcontrol,
  title={Stochastic learning under random reshuffling with constant step-sizes},
  author={Ying Bicheng and Yuan, Kun and Vlaski, Stefan and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={2},
  pages={474--489},
  year={2018},
  publisher={IEEE}
}
@inproceedings{safran2020good,
  title={How good is SGD with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={COLT},
  year={2020}
}

@inproceedings{loizou2021stochastic,
  title={Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity},
  author={Loizou, Nicolas and Berard, Hugo and Gidel, Gauthier and Mitliagkas, Ioannis and Lacoste-Julien, Simon},
  booktitle={NeurIPS},
  year={2021}
}
@inproceedings{daskalakis_complexity,
title = {The complexity of constrained min-max optimization},
author = {Daskalakis, Constantinos and Skoulakis, Stratis and Zampetakis, Manolis},
booktitle = {STOC},
year = {2021}
}
@InProceedings{gower2019sgd,
  title={SGD: General Analysis and Improved Rates}, 
  author={Robert Mansel Gower and Nicolas Loizou and Xun Qian and Alibek Sailanbayev and Egor Shulgin and Peter Richtarik},
  booktitle={AISTATS}, 
  year={2019}
}

@InProceedings{gower2021sgd,
  title = {SGD for Structured Nonconvex Functions: Learning Rates, Minibatching and Interpolation},
  author = {Gower, Robert and Sebbouh, Othmane and Loizou, Nicolas},
  booktitle = {AISTATS},
  year = {2021}
}

@inproceedings{vlatakis2024stochastic,
  title={Stochastic methods in variational inequalities: Ergodicity, bias and refinements},
  author={Vlatakis-Gkaragkounis, Emmanouil Vasileios and Giannou, Angeliki and Chen, Yudong and Xie, Qiaomin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4123--4131},
  year={2024},
  organization={PMLR}
}
@article{khaled2023unified,
  title={Unified analysis of stochastic gradient methods for composite convex and smooth optimization},
  author={Khaled, Ahmed and Sebbouh, Othmane and Loizou, Nicolas and Gower, Robert M and Richt{\'a}rik, Peter},
  journal={Journal of Optimization Theory and Applications},
  volume={199},
  number={2},
  pages={499--540},
  year={2023},
  publisher={Springer}
}


@inproceedings{emmanouilidis2024stochastic,
  title={Stochastic extragradient with random reshuffling: Improved convergence for variational inequalities},
  author={Emmanouilidis, Konstantinos and Vidal, Ren{\'e} and Loizou, Nicolas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3682--3690},
  year={2024},
  organization={PMLR}
}

@article{hao2021gradient,
  title={A gradient descent method for solving a system of nonlinear equations},
  author={Hao, Wenrui},
  journal={Applied Mathematics Letters},
  volume={112},
  pages={106739},
  year={2021},
  publisher={Elsevier}
}
@article{pfau2016connecting,
  title={Connecting generative adversarial networks and actor-critic methods},
  author={Pfau, David and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1610.01945},
  year={2016}
}
@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}
@article{daskalakis2017training,
  title={Training gans with optimism},
  author={Daskalakis, Constantinos and Ilyas, Andrew and Syrgkanis, Vasilis and Zeng, Haoyang},
  journal={arXiv preprint arXiv:1711.00141},
  year={2017}
}
@inproceedings{Bottou2012StochasticGD,
  title={Stochastic Gradient Descent Tricks},
  author={L{\'e}on Bottou},
  booktitle={Neural Networks},
  year={2012}
}
@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@InProceedings{pmlr-v132-abernethy21a,
  title = {Last-Iterate Convergence Rates for Min-Max Optimization: Convergence of Hamiltonian Gradient Descent and Consensus Optimization},
  author =       {Abernethy, Jacob and Lai, Kevin A. and Wibisono, Andre},
  booktitle = 	 {ALT},
  year = 	 {2021}
}
@inproceedings{Bottou2009CuriouslyFC,
  title={Curiously Fast Convergence of some Stochastic Gradient Descent Algorithms},
  author={L{\'e}on Bottou},
  year={2009}
}
@inproceedings{wiki,
    author= {Wikipedia}, 
    title = {Wasserstein metric â€“ wikipedia, the free encyclopedia, 2023},
    publisher = {URL https://en.wikipedia.org/wiki/Wasserstein\_metric}, 
    year={Accessed: 2025-08-28}
}
@book{bertsekas2003convex,
  title={Convex analysis and optimization},
  author={Bertsekas, Dimitri and Nedic, Angelia and Ozdaglar, Asuman},
  volume={1},
  year={2003},
  publisher={Athena Scientific}
}
@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \& Business Media}
}