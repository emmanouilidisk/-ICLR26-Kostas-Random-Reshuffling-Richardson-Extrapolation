% !TEX root = ./iclr2026_conference.tex


\section{Experiments}\vspace{-.25em}
In this section, we conduct a series of experiments demonstrating the effect of benefits from the synergy of the two heuristics empirically. 
More specifically, for the in the strongly monotone setting we compare the relative error and bias attained by 4 variants: the classical SGD(A) algorithm using uniform with-replacement sampling (denoted as \emph{SGDA} in the plots), the one equipped with \RRresh, the one equipped with \RRrom\ and the method utilizing both of the heuristics. 
For each experiment, we report the average of $5$ trials/runs and plot the relative error $\log\left(\frac{\|x_k - x^*\|^2}{\|x_0 - x^*\|^2}\right)$ with respect to the iterations of the algorithm.

\textbf{\textit{Two-player Zero-Sum Games.}} In the strongly monotone case, we consider the two-player zero-sum game from \cite{emmanouilidis2024stochastic, loizou2021stochastic}, consisting a strongly convex - strongly concave quadratic of the form
\begin{eqnarray}
    \min_{x_{1} \in \R^d} \max_{x_{2}\in \R^d} f(x_1, x_2) = \frac{1}{n} \sum_{i=1}^{n} \frac{1}{2} x_1^T A_i x_1 + x_1^T B_i x_2 - \frac{1}{2} x_2^T C_i x^2 + \alpha_i^T x_1 - c_i^T x_2. \nonumber
\end{eqnarray}
For the interested reader, additional details on the experimental setup and the procedure used to sample the matrices $A_i, B_i, C_i$ are provided in Appendix~\ref{app: additional_experiments}.

\textbf{On the Rate of Convergence.} In the first set of experiments, we aim to validate empirically the result of Theorem~\ref{thm: convergence_rate} by running SGDA with \RRresh\ and using the step sizes described by theory. We conduct experiments for multiple conditions $\kappa = \frac{L}{\mu}$ with value $\kappa = \{1, 5, 10\}$ and $\mu = 1$. In Figure~\ref{fig: rate_of_conv}, we observe that the algorithm with \RRresh\ converges linearly to a neighbourhood around the solution $x^*$ and the neighbourhood depends on the step size used, validating in this way the results of Theorem~\ref{thm: convergence_rate}. We have run experiments also for stepsizes that are larger than the ones predicted in theory, observing similar behaviour of the optimization algorithm. Additionally, we have performed an ablation study in Wasserstein GANs \citep{emmanouilidis2024stochastic, daskalakis2017training}, showing that the performance benefit of the proposed heuristic is universal in many other common optimization algorithms used in VIs (Appendix~\ref{app: additional_experiments}).

\begin{figure}
    \centering
    \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/relative_error_plots/new_plot_manolis_gamma_0.0013714594258871589_condition_num_1.pdf.pdf}
    \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/relative_error_plots/new_plot_manolis_gamma_0.00037627352424815026_condition_num_5.pdf.pdf}
    \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/relative_error_plots/new_plot_manolis_gamma_0.0001_condition_num_10.pdf.pdf}
        \vspace{-1em}
    \caption{Comparison of different heuristics. The \RRresh\ combination of \RRrom$\oplus$\RRresh\ converges to linearly to neighborhood of the solution, validating the established theoretical results (Theorem~\ref{thm: convergence_rate}). Even when we are using the last iterates, the combination of \RRrom$\oplus$\RRresh\ converges to a smaller relative error a smaller relative error in comparison to the other variants (classical SGDA, \RRresh, \RRrom). This validates that bias of Algorithm~\ref{alg:rrrom-rrresh} is improved even when \RRresh-last iterates are used. }
    \label{fig: rate_of_conv}
    \vspace{-1em}
\end{figure}
% \textbf{Bias Reduction: \textit{Which heuristic is empirically better?}} In a second set of experiments, we examine the effect of each heuristic (\RRresh, \RRrom, $\RRrom \oplus \RRresh$) in the bias attained. More specifically, we run each variant of the method for multiple step sizes in the range $\gamma \in [10^{-5}, 10^{-3}]$ and plot the induced bias term with respect to the step size in logarithmic scale. In Figure~\ref{?}, we observe that the algorithm with \RRresh attains lower bias than the plain variant of SGD and the proposed method \RRrom$\oplus$\RRresh achieves the more refined improvement compared to all variants, validating in this way our theoretical results.     

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/relative_error_plots/new_plot_manolis_gamma_0.001_condition_num_1.pdf.pdf}
%     \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/new_plot_manolis_gamma_0.0001_condition_num_5.pdf.pdf}
%     \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/new_plot_manolis_gamma_0.0001_condition_num_10.pdf.pdf}\\
%     \caption{Comparison of different heuristics. The combination of \RRrom$\oplus$\RRresh converges to a smaller relative error in comparison to the other variants (classical SGDA, \RRresh, \RRrom). }
%     \label{fig:placeholder}
% \end{figure}

\textbf{Efficient Statistics \& Empirical Concentration.} This set of experiments examines the central limit theorem (CLT) and aims to validate empirically the theoretical results established in Theorem~\ref{thm: LLN_CLT_res}. The value of the game, which is zero, is used as the test value for which we observe the averaged evaluations after $T = \{100, 500, 1000\}$ iterations respectively. In particular, we run the algorithm with the step size suggested by Theorem~\ref{thm: LLN_CLT_res} and maintain for the total number of iterations the sum of the evaluations, normalized with $\sqrt{T}$. We run the experiment for $T = 2000$ trials/runs and plot the corresponding histograms. In Figure~\ref{fig: clt_validation}, we observe that the histograms tend to concentrate to the value of the game as the number of iterations increase. Additionally, we examine the effect of the step size to concentration of the observed distributions. 
% Lastly, we test the effect of the step size in the resulting distribution. We run the algorithm for step sizes $\gamma = \{0.001, 0.1\}$ and compare the concentration attained in each case. We observe that 
\vspace{-0.5em}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.35\linewidth]{iclr2026_4Rs/figures/concentration/fig3_sgda (4).pdf}
    \includegraphics[width=0.3\linewidth]{iclr2026_4Rs/figures/concentration/fig4_sgda (4).pdf}
        \vspace{-1.5em}
    \caption{Validation of concentration around the mean and effect of the number of iterations and step sized selected. The average of the game values tend to concentrate more around the mean for larger number of iterations and smaller step sizes. The right plot indicates the effect of two different step sizes $\gamma \in \{0.1, 0.001\}$, showing that for smaller step sizes the corresponding distribution attains higher concentration around the mean of the values. 
    }
        \vspace{-1em}

    \label{fig: clt_validation}
\end{figure}
