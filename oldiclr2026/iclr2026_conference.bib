@inproceedings{
cho2023sgda,
title={{SGDA} with shuffling: faster convergence for nonconvex-P{\L} minimax optimization},
author={Hanseul Cho and Chulhee Yun},
booktitle={ICLR},
year={2023}
}
@inproceedings{loizou2020stochastic,
  title={Stochastic hamiltonian gradient methods for smooth games},
  author={Loizou, Nicolas and Berard, Hugo and Jolicoeur-Martineau, Alexia and Vincent, Pascal and Lacoste-Julien, Simon and Mitliagkas, Ioannis},
  booktitle={ICML},
  year={2020}
}

@article{chen1997convergence,
  title={Convergence rates in forward--backward splitting},
  author={Chen, George HG and Rockafellar, R Tyrrell},
  journal={SIAM Journal on Optimization},
  volume={7},
  number={2},
  pages={421--444},
  year={1997},
  publisher={SIAM}
}

@inproceedings{
pethick2022escaping,
title={Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems},
author={Thomas Pethick and Puya Latafat and Panos Patrinos and Olivier Fercoq and Volkan Cevher},
booktitle={ICLR},
year={2022}
}
@inproceedings{yu2022fast,
  title={Fast Distributionally Robust Learning with Variance-Reduced Min-Max Optimization},
  author={Yu, Yaodong and Lin, Tianyi and Mazumdar, Eric V and Jordan, Michael},
  booktitle={AISTATS},
  year={2022}
}
@inproceedings{mishchenko2020revisiting,
  title={Revisiting stochastic extragradient},
  author={Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  booktitle={AISTATS},
  year={2020}
}

@inproceedings{namkoong2016stochastic,
  title={Stochastic gradient methods for distributionally robust optimization with f-divergences},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={NeurIPS},
  year={2016}
}

@inproceedings{brown2020combining,
  title={Combining deep reinforcement learning and search for imperfect-information games},
  author={Brown, Noam and Bakhtin, Anton and Lerer, Adam and Gong, Qucheng},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{sokota2022unified,
  title={A unified approach to reinforcement learning, quantal response equilibria, and two-player zero-sum games},
  author={Sokota, Samuel and D'Orazio, Ryan and Kolter, J Zico and Loizou, Nicolas and Lanctot, Marc and Mitliagkas, Ioannis and Brown, Noam and Kroer, Christian},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{wang2021adversarial,
  title={Adversarial attack generation empowered by min-max optimization},
  author={Wang, Jingkang and Zhang, Tianyun and Liu, Sijia and Chen, Pin-Yu and Xu, Jiacen and Fardad, Makan and Li, Bo},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{goodfellow2014generative,
title={Generative adversarial nets},
author={Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle={NeurIPS},
year={2014}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, A. and Makelov, A. and Schmidt, L. and Tsipras, D. and Vladu, A.},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={ICML},
  year={2017}
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@article{han2023riemannian,
  title={Riemannian Hamiltonian methods for min-max optimization on manifolds},
  author={Han, Andi and Mishra, Bamdev and Jawanpuria, Pratik and Kumar, Pawan and Gao, Junbin},
  journal={SIAM Journal on Optimization},
  volume={33},
  number={3},
  pages={1797--1827},
  year={2023},
  publisher={SIAM}
}

@inproceedings{balduzzi2018mechanics,
  title={The mechanics of n-player differentiable games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  booktitle={ICML},
  year={2018}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{gorbunov2022last,
  title={Last-iterate convergence of optimistic gradient method for monotone variational inequalities},
  author={Gorbunov, Eduard and Taylor, Adrien and Gidel, Gauthier},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{gorbunov2022stochastic,
  title={Stochastic extragradient: General analysis and improved rates},
  author={Gorbunov, Eduard and Berard, Hugo and Gidel, Gauthier and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2022}
}

@inproceedings{beznosikov2022stochastic,
  title={Stochastic gradient descent-ascent: Unified theory and new efficient methods},
  author={Beznosikov, Aleksandr and Gorbunov, Eduard and Berard, Hugo and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2023}
}
@inproceedings{daskalakis2018limit,
  title={The limit points of (optimistic) gradient descent in min-max optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  booktitle={NeurIPS},
  year={2018}
}

@article{popov1980modification,
  title={A modification of the Arrow-Hurwicz method for search of saddle points},
  author={Popov, Leonid Denisovich},
  journal={Mathematical notes of the Academy of Sciences of the USSR},
  volume={28},
  number={5},
  pages={845--848},
  year={1980},
  publisher={Springer}
}

@misc{diakonikolas2021efficient,
      title={Efficient Methods for Structured Nonconvex-Nonconcave Min-Max Optimization}, 
      author={Jelena Diakonikolas and Constantinos Daskalakis and Michael I. Jordan},
      year={2021},
        booktitle={AISTATS},
}
@misc{emmanouilidis2024stochastic,
      title={Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities}, 
      author={Konstantinos Emmanouilidis and René Vidal and Nicolas Loizou},
      year={2024},
      booktitle={AISTATS}
}
@misc{huang2023monotonevariationalinequalitiessolution,
      title={Beyond Monotone Variational Inequalities: Solution Methods and Iteration Complexities}, 
      author={Kevin Huang and Shuzhong Zhang},
      year={2023}
}
@misc{karimi2020linearconvergencegradientproximalgradient,
      title={Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\L{}ojasiewicz Condition}, 
      author={Hamed Karimi and Julie Nutini and Mark Schmidt},
      year={2020}
}

@inproceedings{gorbunov2022extragradient,
  title={Extragradient method: O (1/k) last-iterate convergence for monotone variational inequalities and connections with cocoercivity},
  author={Gorbunov, Eduard and Loizou, Nicolas and Gidel, Gauthier},
  booktitle={AISTATS},
    year={2022}
}

@inproceedings{pethick2023solving,
  title={Solving stochastic weak Minty variational inequalities without increasing batch size},
  author={Pethick, Thomas Michaelsen and Fercoq, Olivier and Latafat, Puya and Patrinos, Panagiotis and Cevher, Volkan},
  booktitle={ICLR},
  year={2023}
}

@article{cai2023empirical,
  title={Empirical Risk Minimization with Shuffled SGD: A Primal-Dual Perspective and Improved Bounds},
  author={Cai, Xufeng and Lin, Cheuk Yin and Diakonikolas, Jelena},
  journal={arXiv:2306.12498},
  year={2023}
}

@article{song2020optimistic,
  title={Optimistic dual extrapolation for coherent non-monotone variational inequalities},
  author={Song, Chaobing and Zhou, Zhengyuan and Zhou, Yichao and Jiang, Yong and Ma, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14303--14314},
  year={2020}
}

@article{erdogdu2018global,
  title={Global non-convex optimization with discretized diffusions},
  author={Erdogdu, Murat A and Mackey, Lester and Shamir, Ohad},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@article{tan2023online,
  title={Online stochastic gradient descent with arbitrary initialization solves non-smooth, non-convex phase retrieval},
  author={Tan, Yan Shuo and Vershynin, Roman},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={58},
  pages={1--47},
  year={2023}
}
@inproceedings{raginsky2017non,
  title={Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1674--1703},
  year={2017},
  organization={PMLR}
}
@article{nguyen2021unified,
  title={A unified convergence analysis for shuffling-type gradient methods},
  author={Nguyen, Lam M and Tran-Dinh, Quoc and Phan, Dzung T and Nguyen, Phuong Ha and Van Dijk, Marten},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={9397--9440},
  year={2021},
  publisher={JMLRORG}
}

@article{mertikopoulos2019learning,
  title={Learning in games with continuous action sets and unknown payoff functions},
  author={Mertikopoulos, Panayotis and Zhou, Zhengyuan},
  journal={Mathematical Programming},
  volume={173},
  number={1},
  pages={465--507},
  year={2019},
  publisher={Springer}
}
@inproceedings{beznosikov2022distributed,
  title={Distributed methods with compressed communication for solving variational inequalities, with theoretical guarantees},
  author={Beznosikov, Aleksandr and Richt{\'a}rik, Peter and Diskin, Michael and Ryabinin, Max and Gasnikov, Alexander},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{choudhury2023single,
 title={Single-Call Stochastic Extragradient Methods for Structured Non-monotone Variational Inequalities: Improved Analysis under Weaker Conditions},
 author={Sayantan Choudhury and Eduard Gorbunov and Nicolas Loizou},
 booktitle={NeurIPS},
 year={2023}
}

@inproceedings{zhang2023communication,
  title={Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates},
  author={Zhang, Siqi and Choudhury, Sayantan and Stich, Sebastian U and Loizou, Nicolas},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{hsieh2019convergence,
  title={On the convergence of single-call stochastic extra-gradient methods},
  author={Hsieh, Yu-Guan and Iutzeler, Franck and Malick, J{\'e}r{\^o}me and Mertikopoulos, Panayotis},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{li2022convergence,
  title={On the convergence of stochastic extragradient for bilinear games using restarted iteration averaging},
  author={Li, Chris Junchi and Yu, Yaodong and Loizou, Nicolas and Gidel, Gauthier and Ma, Yi and Le Roux, Nicolas and Jordan, Michael},
  booktitle={AISTATS},
    year={2022}
}

@inproceedings{mishchenko2020random,
  title={Random reshuffling: Simple analysis with vast improvements},
  author={Mishchenko, Konstantin and Khaled, Ahmed and Richt{\'a}rik, Peter},
  booktitle={NeurIPS},
  year={2020}
}
@article{korpelevich1976extragradient,
  title={The extragradient method for finding saddle points and other problems},
  author={Korpelevich, Galina M},
  journal={Matecon},
  volume={12},
  pages={747--756},
  year={1976}
}

@article{juditsky2011solving,
  title={Solving variational inequalities with stochastic mirror-prox algorithm},
  author={Juditsky, Anatoli and Nemirovski, Arkadi and Tauvel, Claire},
  journal={Stochastic Systems},
  volume={1},
  number={1},
  pages={17--58},
  year={2011},
  publisher={INFORMS}
}
@inproceedings{ahn2020sgd,
  title={Sgd with shuffling: optimal rates without component convexity and large epoch requirements},
  author={Ahn, Kwangjun and Yun, Chulhee and Sra, Suvrit},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{lin2020finite,
  title={Finite-time last-iterate convergence for multi-agent learning in games},
  author={Lin, Tianyi and Zhou, Zhengyuan and Mertikopoulos, Panayotis and Jordan, Michael},
  booktitle={ICML},
  year={2020}
}
@inproceedings{lin2020gradient,
  title={On gradient descent ascent for nonconvex-concave minimax problems},
  author={Lin, Tianyi and Jin, Chi and Jordan, Michael},
  booktitle={ICML},
    year={2020}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={AISTATS},
  year={2017}
}
@article{necoara2019linear,
  title={Linear convergence of first order methods for non-strongly convex optimization},
  author={Necoara, Ion and Nesterov, Yu and Glineur, Francois},
  journal={Mathematical Programming},
  volume={175},
  pages={69--107},
  year={2019},
  publisher={Springer}
}
@inproceedings{hsieh2020explore,
  title={Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling},
  author={Hsieh, Yu-Guan and Iutzeler, Franck and Malick, J{\'e}r{\^o}me and Mertikopoulos, Panayotis},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{beznosikov2023stochastic,
  title={Stochastic gradient descent-ascent: Unified theory and new efficient methods},
  author={Beznosikov, Aleksandr and Gorbunov, Eduard and Berard, Hugo and Loizou, Nicolas},
  booktitle={AISTATS},
  year={2023}
}
@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={ICLR},
year={2018}
}
@inproceedings{
chavdarova2021taming,
title={Taming {GAN}s with Lookahead-Minmax},
author={Tatjana Chavdarova and Matteo Pagliardini and Sebastian U Stich and Fran{\c{c}}ois Fleuret and Martin Jaggi},
booktitle={ICLR},
year={2021}
}
@article{Neumann1928,
author = {Neumann, J. von},
journal = {Mathematische Annalen},
pages = {295-320},
title = {Zur Theorie der Gesellschaftsspiele},
volume = {100},
year = {1928},
}
@article{Blackwell1956AnAO,
  title={An analog of the minimax theorem for vector payoffs.},
  author={David Blackwell},
  journal={Pacific Journal of Mathematics},
  year={1956},
  volume={6},
  pages={1-8}
}
@article{
bohm2023solving,
title={Solving Nonconvex-Nonconcave Min-Max Problems exhibiting Weak Minty Solutions},
author={Axel B{\"o}hm},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023}
}
@misc{cai2022tight,
      title={Tight Last-Iterate Convergence of the Extragradient and the Optimistic Gradient Descent-Ascent Algorithm for Constrained Monotone Variational Inequalities}, 
      author={Yang Cai and Argyris Oikonomou and Weiqiang Zheng},
      year={2022},
      archivePrefix={arXiv },
      eprint={2204.09228}
}
@inproceedings{das2022sampling,
  title={Sampling without replacement leads to faster rates in finite-sum minimax optimization},
  author={Das, Aniket and Sch{\"o}lkopf, Bernhard and Muehlebach, Michael},
  booktitle={NeurIPS},
  year={2022}
}
@inproceedings{Jain2019SGDWR,
  title={SGD without Replacement: Sharper Rates for General Smooth Convex Functions},
  author={Prateek Jain and Dheeraj M. Nagaraj and Praneeth Netrapalli},
  booktitle={ICML},
  year={2019}
}
@inproceedings{Yang2020GlobalCA,
  title={Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems},
  author={Junchi Yang and Negar Kiyavash and Niao He},
  booktitle={NeurIPS},
  year={2020}
}
@article{gurbuzbalaban2021random,
  title={Why random reshuffling beats stochastic gradient descent},
  author={G{\"u}rb{\"u}zbalaban, Mert and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={Mathematical Programming},
  volume={186},
  pages={49--84},
  year={2021},
  publisher={Springer}
}

@inproceedings{Yang2020GlobalCA,
  title={Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems},
  author={Junchi Yang and Negar Kiyavash and Niao He},
  booktitle={NeurIPS},
  year={2020}
}
@inproceedings{haochen2019random,
  title={Random shuffling beats sgd after finite epochs},
  author={Haochen, Jeff and Sra, Suvrit},
  booktitle={ICML},
  year={2019}
}
@article{RRSGDcontrol,
  title={Stochastic learning under random reshuffling with constant step-sizes},
  author={Ying Bicheng and Yuan, Kun and Vlaski, Stefan and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={2},
  pages={474--489},
  year={2018},
  publisher={IEEE}
}
@inproceedings{safran2020good,
  title={How good is SGD with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={COLT},
  year={2020}
}

@inproceedings{loizou2021stochastic,
  title={Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity},
  author={Loizou, Nicolas and Berard, Hugo and Gidel, Gauthier and Mitliagkas, Ioannis and Lacoste-Julien, Simon},
  booktitle={NeurIPS},
  year={2021}
}
@inproceedings{daskalakis_complexity,
title = {The complexity of constrained min-max optimization},
author = {Daskalakis, Constantinos and Skoulakis, Stratis and Zampetakis, Manolis},
booktitle = {STOC},
year = {2021}
}
@InProceedings{gower2019sgd,
  title={SGD: General Analysis and Improved Rates}, 
  author={Robert Mansel Gower and Nicolas Loizou and Xun Qian and Alibek Sailanbayev and Egor Shulgin and Peter Richtarik},
  booktitle={AISTATS}, 
  year={2019}
}

@InProceedings{gower2021sgd,
  title = {SGD for Structured Nonconvex Functions: Learning Rates, Minibatching and Interpolation},
  author = {Gower, Robert and Sebbouh, Othmane and Loizou, Nicolas},
  booktitle = {AISTATS},
  year = {2021}
}

@inproceedings{vlatakis2024stochastic,
  title={Stochastic methods in variational inequalities: Ergodicity, bias and refinements},
  author={Vlatakis-Gkaragkounis, Emmanouil Vasileios and Giannou, Angeliki and Chen, Yudong and Xie, Qiaomin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4123--4131},
  year={2024},
  organization={PMLR}
}
@article{khaled2023unified,
  title={Unified analysis of stochastic gradient methods for composite convex and smooth optimization},
  author={Khaled, Ahmed and Sebbouh, Othmane and Loizou, Nicolas and Gower, Robert M and Richt{\'a}rik, Peter},
  journal={Journal of Optimization Theory and Applications},
  volume={199},
  number={2},
  pages={499--540},
  year={2023},
  publisher={Springer}
}
@article{hao2021gradient,
  title={A gradient descent method for solving a system of nonlinear equations},
  author={Hao, Wenrui},
  journal={Applied Mathematics Letters},
  volume={112},
  pages={106739},
  year={2021},
  publisher={Elsevier}
}
@article{pfau2016connecting,
  title={Connecting generative adversarial networks and actor-critic methods},
  author={Pfau, David and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1610.01945},
  year={2016}
}
@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}
@article{daskalakis2017training,
  title={Training gans with optimism},
  author={Daskalakis, Constantinos and Ilyas, Andrew and Syrgkanis, Vasilis and Zeng, Haoyang},
  journal={arXiv preprint arXiv:1711.00141},
  year={2017}
}
@inproceedings{Bottou2012StochasticGD,
  title={Stochastic Gradient Descent Tricks},
  author={L{\'e}on Bottou},
  booktitle={Neural Networks},
  year={2012}
}
@InProceedings{pmlr-v132-abernethy21a,
  title = {Last-Iterate Convergence Rates for Min-Max Optimization: Convergence of Hamiltonian Gradient Descent and Consensus Optimization},
  author =       {Abernethy, Jacob and Lai, Kevin A. and Wibisono, Andre},
  booktitle = 	 {ALT},
  year = 	 {2021}
}
@inproceedings{Bottou2009CuriouslyFC,
  title={Curiously Fast Convergence of some Stochastic Gradient Descent Algorithms},
  author={L{\'e}on Bottou},
  year={2009}
}
@inproceedings{wiki,
    author= {Wikipedia}, 
    title = {Wasserstein metric – wikipedia, the free encyclopedia, 2023},
    publisher = {URL https://en.wikipedia.org/wiki/Wasserstein\_metric}, 
    year={Accessed: 2025-08-28}
}
@book{bertsekas2003convex,
  title={Convex analysis and optimization},
  author={Bertsekas, Dimitri and Nedic, Angelia and Ozdaglar, Asuman},
  volume={1},
  year={2003},
  publisher={Athena Scientific}
}
@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \& Business Media}
}